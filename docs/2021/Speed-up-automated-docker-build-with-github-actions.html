<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="apple-mobile-web-app-capable" content="yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title> nicolabs | Speed up your automated Docker builds with GitHub Actions </title> <meta name="description" content=" Work in progress... "> <meta name="keywords" content="android, development, java, javascript, python, web"> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <!-- Social: Facebook / Open Graph --> <meta property="og:type" content="article"> <meta property="article:author" content="nicobo"> <meta property="article:section" content=""> <meta property="article:tag" content=""> <meta property="article:published_time" content="2021-03-23 00:00:00 +0100"> <meta property="og:url" content="https://www.nicolabs.net/2021/Speed-up-automated-docker-build-with-github-actions"> <meta property="og:title" content=" nicolabs | Speed up your automated Docker builds with GitHub Actions "> <meta property="og:image" content="https://www.nicolabs.net"> <meta property="og:description" content=" Work in progress... "> <meta property="og:site_name" content="nicobo"> <meta property="og:locale" content="en_US"> <!-- Social: Twitter --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:site" content="nic0b0"> <meta name="twitter:title" content=" nicolabs | Speed up your automated Docker builds with GitHub Actions "> <meta name="twitter:description" content=" Work in progress... "> <meta name="twitter:image:src" content="https://www.nicolabs.net"> <!-- Social: Google+ / Schema.org --> <meta itemprop="name" content=" nicolabs | Speed up your automated Docker builds with GitHub Actions "> <meta itemprop="description" content=" Work in progress... "> <meta itemprop="image" content="https://www.nicolabs.net"> <!-- rel prev and next --> <link rel="stylesheet" href="/assets/css/main.css"> <!-- Canonical link tag --> <link rel="canonical" href="https://www.nicolabs.net/2021/Speed-up-automated-docker-build-with-github-actions"> <link type="application/atom+xml" rel="alternate" href="https://www.nicolabs.net/feed.xml" title="nicolabs" /> <script type="text/javascript"> var disqus_shortname = 'nicolabs'; </script> <!-- Enable displaying pictures in full size using the Fullscreen API --> <!-- A polyfill that also simplifies the API. TODO maybe there are others closer to the norm and with more features. Still chances are this will not work on iPhone without using a full-fledged Js library. --> <script src="/assets/lib/screenfull.js/dist/screenfull.min.js"></script> <!-- This code selects which elements and how fullscreen is triggered --> <script> document.addEventListener("DOMContentLoaded", function(event) { var els = document.getElementsByClassName("plantuml"); for ( var e=0 ; e<els.length ; e++ ) { var el = els[e]; el.addEventListener('click', function() { if (screenfull.isEnabled) { screenfull.toggle(el); el.classList.toggle("fullscreen"); } else { console.log("Fullscreen not supported"); } }); } }); </script> <script> window.onscroll = function() { if (document.body.scrollTop > 0 || document.documentElement.scrollTop > 0) { document.querySelector('.site-header').classList.add('site-header-pinned'); } else { document.querySelector('.site-header').classList.remove('site-header-pinned'); } }; </script> </head> <body> <main class="wrapper"> <header class="site-header"> <nav class="nav"> <div class="container"> <h1 class="logo"><a href="/">nico<span>labs</span></a></h1> <ul class="navbar"> <li><a href="/about">about</a></li> <li><a href="/articles">articles</a></li> <li><a href="/feed.xml">feed</a></li> </ul> </div> </nav> </header> <article class="post container" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <h1 class="post-title" itemprop="name headline">Speed up your automated Docker builds with GitHub Actions</h1> <p class="post-meta"> <a href="https://github.com/nicolabs/nicolabs.github.io/commits/master/_preposts/2021-03-23-Speed-up-automated-docker-build-with-github-actions.md" title="Read full history of this post"> <time class="datePublished" datetime="2021-03-23T00:00:00+01:00" itemprop="datePublished">Mar 23, 2021</time> </a> <span class="post-meta-separator">•</span> <span itemprop="read_time"> 15 minutes read </span> <span class="post-meta-separator">•</span> <span itemprop="maturity"><a href="/2016/Migrating-from-Drupal-to-Jekyll" title="Maturity of this article : draft < good < stable or deprecated&#xa;Click for the explanation.">Maturity : <span class="maturity-label maturity-draft" title="Maturity of this article : draft < good < stable or deprecated">draft</span> </span></a> </p> </header> <div class="post-content" itemprop="articleBody"> <p><img src="/assets/blog/3rdparty/pictures/happy_international_cat_day___by_bloglaurel_dbjdmqm.jpg" alt="Docker &amp; cats illustration by bloglaurel - https://www.deviantart.com/bloglaurel/art/Happy-International-Cat-Day-697676638" width="100%" /></p> <figcaption>Docker &amp; cats illustration by bloglaurel - https://www.deviantart.com/bloglaurel/art/Happy-International-Cat-Day-697676638</figcaption> <h2 id="introduction">Introduction</h2> <p>The <a href="https://docs.docker.com/ci-cd/github-actions/">universally</a> <a href="https://www.docker.com/blog/docker-github-actions/">advertized</a> <a href="https://docs.github.com/en/actions/guides/publishing-docker-images">way</a> of building Docker images with GitHub is to set up a <a href="https://docs.github.com/en/actions"><strong>GitHub Actions</strong></a> workflow.</p> <p><em>Github Actions</em> (GA) is actually very easy to use but nonetheless still <a href="https://github.com/actions/cache/graphs/code-frequency">under heavy development</a>.</p> <p>Unfortunately, almost all tutorials out there are based on (the same) very simplistic use cases. I just couldn’t get it right by simply following them : I’ve literally spent hours to test and understand how to <em>leverage the cache action for Docker multi-stage builds</em>.</p> <p>I hope this post will be useful to anyone with a similar use case.</p> <!--more--> <p>This article will <em>not</em> describe how to make your first GA workflow. We will look at <em>traps to avoid</em> when <strong>building multiple and multi-stage Docker images with GA</strong>, essentially covering caching, and more specifically using <em>actions/cache@v2</em>.</p> <h2 id="use-parallelism">Use parallelism</h2> <p>The first thing to take care of when building multiple images is to run tasks in parallel, whenever possible :</p> <ul> <li> <p>Docker’s <em>buildx</em> command already takes care of <a href="https://docs.docker.com/buildx/working-with-buildx/#build-multi-platform-images">multi-platform parallel building</a> so <strong>using <a href="https://github.com/docker/build-push-action">docker/build-push-action@v2</a> in your workflow is the way to go</strong>.</p> </li> <li> <p>You will also need to figure out how you can <strong>split your build in several <em>workflows</em> or <em>jobs</em></strong>. <a href="https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions">In GA, workflows run in parallel, as well as jobs inside a workflow</a>, by default.</p> </li> </ul> <p>Let’s consider my use case. I have 3 images : <em>alpine</em>, <em>debian</em> and <em>signal-debian</em>, from which the first one : <em>alpine</em>, has no dependency on the 2 others.</p> <p>Building them sequentially (as subsequent <em>steps</em> in a <em>job</em>) resulted in 1h50 runs… By simply building the <em>alpine</em> image in its own job <strong>I saved 40 min</strong> (the duration of the <em>alpine</em> build) !</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>

  <span class="na">build-publish-alpine</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">Build, Publish alpine</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">prod</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout</span>
      <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v2</span>

  <span class="s">...</span>

  <span class="c1"># This job will run in parallel of build-push-alpine</span>
  <span class="na">build-publish-debian</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">Build, Publish debian</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">prod</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout</span>
      <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v2</span>
</code></pre></div></div> <p>I leave it up to you to look at <a href="https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobs">the documentation</a> :</p> <ul> <li>ordering with <a href="https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idneeds">jobs.&lt;job_id&gt;.needs</a></li> <li>can mutualize variables, steps, outputs, …</li> </ul> <h2 id="use-caching">Use caching</h2> <p>Building Docker images on your local machine uses cache by default. If your Dockerfile is correctly crafted this DRASTICALLY enhances build time. In my case, building from scratch takes up hours. My first concern was therefore to ensure my Dockerfiles were always <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache">cache-optimized</a>.</p> <p>When building with GitHub Actions however, caching is not straightforward.</p> <p>Let’s start with a conceptual difference between :</p> <ol> <li> <p><strong>sharing cache during the build</strong> (e.g. image1 you just built which is also the base image of image2 in the <em>same</em> workflow) - doing this reduces build duration when using the same layers multiple times during the build (multi-arch builds probably do)</p> </li> <li> <p><strong>reusing cache from previous builds</strong> - when you push a small modification in your code and the images have to be rebuilt, you would probably be grateful to get back the cache from the previous push, which was from <em>a past</em> workflow</p> </li> </ol> <p>There are two ways to cache data with GitHub actions : <a href="https://docs.github.com/en/actions/guides/storing-workflow-data-as-artifacts">upload-artifact and download-artifacts</a> actions and <a href="https://github.com/actions/cache">actions/cache</a> action.</p> <p>Although <em>actions/upload-artifact</em> and <em>actions/download-artifact</em> might be able to cover both points above, it is not meant to cache docker layers. <a href="https://docs.github.com/en/actions/guides/caching-dependencies-to-speed-up-workflows#comparing-artifacts-and-dependency-caching">The major recommended approach I’ve seen</a> is to use <strong>actions/cache@v2</strong>, which also covers the two concepts.</p> <blockquote> <p><strong>NOTE</strong> In theory, the ‘artifact’ approach should also work, but is not advertized for this kind of usage. This is maybe the premises of a future update to this article.</p> </blockquote> <h3 id="set-modemax">Set mode=max</h3> <p>Common snippets found on the web for the <em>docker/build-push-action</em> <strong>will only cache final Docker images</strong> :</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build and push</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">docker_build</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/build-push-action@v2</span>
  <span class="na">with</span><span class="pi">:</span>
    <span class="na">context</span><span class="pi">:</span> <span class="s">./</span>
    <span class="na">file</span><span class="pi">:</span> <span class="s">./Dockerfile</span>
    <span class="na">builder</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">push</span><span class="pi">:</span> <span class="no">true</span>
    <span class="na">tags</span><span class="pi">:</span>  <span class="s">ushamandya/simplewhale:latest</span>
    <span class="na">cache-from</span><span class="pi">:</span> <span class="s">type=local,src=/tmp/.buildx-cache</span>
    <span class="na">cache-to</span><span class="pi">:</span> <span class="s">type=local,dest=/tmp/.buildx-cache</span>
</code></pre></div></div> <p>If you deal with multi-stage Dockerfiles, you SHOULD absolutely <a href="https://github.com/docker/buildx#--cache-tonametypetypekeyvalue">set <code class="language-plaintext highlighter-rouge">mode=max</code> attribute on the <code class="language-plaintext highlighter-rouge">cache-to</code> entry to enable caching of layers from all stages</a> :</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="na">cache-to</span><span class="pi">:</span> <span class="s">type=local,dest=/tmp/.buildx-cache,mode=max</span>
</code></pre></div></div> <p>For me, this reduced the build time of individual jobs using the cache <strong>from ~45 minutes to 5-10 minutes !</strong></p> <h3 id="there-is-an-overhead">There is an overhead</h3> <p>With this technique, subsequent runs of the same job will still vary (this is why I’ve stated a 5-10 min. variation above). It is due to <em>actions/cache</em>, which saves and retrieves the cache from a remote storage (S3 or alike). <strong>The more the cache grows, the longer it takes to get and save it.</strong></p> <p>I’ve observed varying overheads from 1 min. for a 2GB cache, up to 7 min. for a 4GB+ cache (including both download and upload). Repeat this for every job…</p> <p>The exact pattern depends on what you put in the cache but this is something you should definitely keep in mind, as caching may not be worth it, for instance if your build is fast and uses a large cache.</p> <h3 id="there-is-a-size-limit">There is a size limit</h3> <p>GitHub offers 5GB of storage : when this limit is reached or a week has passed, old caches will be deleted (based on their key).</p> <p>This can be problematic if you build generates a large cache, because the closer your build reaches this limit on each run, the less you will benefit from it, as recent data will be deleted before they can be used.</p> <p>The worst case happened to me : I was building 3 images using multi-stage builds and including large base image : the build typically exceeded the 5GB limit on each run and at least one of the 3 caches was deleted everytime, meaning that only 1 or 2 images could reuse the cache from the previous run.</p> <p>In the worst case, if your build always exceeds the cache limit, the cache will be discarded everytime and you will only be able to get some benefit from within a job, not between two subsequent runs.</p> <p>Your best bet to overcome this limit would probably be to use self-hosted runners or external storage (e.g. AWS), however if you feel up to it here are some tips :</p> <ul> <li>you may observe <code class="language-plaintext highlighter-rouge">No space left on device</code> errors when you reach the max. cache size. It is very annoying but you may be able to bypass this by moving the cache to another mount point with more space (make a step <code class="language-plaintext highlighter-rouge">run: sudo df -h</code> to check ; I’ve observed <code class="language-plaintext highlighter-rouge">/</code> with 22 GB free on my setup)</li> <li>you may try to split into more jobs (so smaller caches) to prevent the filesystem to fill up and crash, as it seems that eviction is not done while the runner is alive.</li> <li><code class="language-plaintext highlighter-rouge">mode=max</code> can highly increase the cache’s size and cause errors or early evictions : you may find the default mode a good compromise for your usage</li> <li>insert <a href="https://github.community/t/how-to-clear-cache-in-github-actions/129038/5">a custom variable in the cache’s key</a> so that you can reset it if your build is stuck because of a corrupted cache</li> <li>maybe you should use multiple GitHub projects rather than a single one (e.g. one Dockerfile per project, if it’s not overkill)</li> </ul> <h4 id="sample-workflow-that-could-be-split-into-several-jobs">Sample workflow that could be split into several jobs</h4> <p>In the example below, 2 steps share the same cache. If the 1st step ‘docker_build_debian’ fills up the cache with 5GB of docker layers, the 2nd step ‘docker_build_alpine’ will likely not be able to add more content to the cache and will either crash or be discarded by GitHub prior to the next run, forcing it to start again from an empty cache.</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache Docker layers</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v2</span>
  <span class="na">with</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/tmp/.buildx-cache</span>
      <span class="na">key</span><span class="pi">:</span> <span class="s">$-buildx-debian-$</span>
      <span class="na">restore-keys</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">$-buildx-debian-</span>
        <span class="s">$-buildx-</span>

<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build and push debian</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">docker_build_debian</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/build-push-action@v2</span>
  <span class="na">with</span><span class="pi">:</span>
      <span class="na">context</span><span class="pi">:</span> <span class="s">./</span>
      <span class="na">file</span><span class="pi">:</span> <span class="s">./debian.Dockerfile</span>
      <span class="na">builder</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">push</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">cache-from</span><span class="pi">:</span> <span class="s">type=local,src=/tmp/.buildx-cache</span>
      <span class="na">cache-to</span><span class="pi">:</span> <span class="s">type=local,dest=/tmp/.buildx-cache,mode=max</span>

<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build and push alpine</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">docker_build_alpine</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/build-push-action@v2</span>
  <span class="na">with</span><span class="pi">:</span>
      <span class="na">context</span><span class="pi">:</span> <span class="s">./</span>
      <span class="na">file</span><span class="pi">:</span> <span class="s">./alpine.Dockerfile</span>
      <span class="na">builder</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">push</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">cache-from</span><span class="pi">:</span> <span class="s">type=local,src=/tmp/.buildx-cache</span>
      <span class="na">cache-to</span><span class="pi">:</span> <span class="s">type=local,dest=/tmp/.buildx-cache,mode=max</span>
</code></pre></div></div> <h3 id="the-key-to-cache-matching">The key to cache matching</h3> <p>The <em>actions/cache</em> matching algorithm is based on the cache’s <em>key</em>, which could be thought as a branch in a tree : from the trunk to the leafs, the latter representing the most specific cache. If your build does not match or evict the cache as expected, I encourage you to <a href="https://docs.github.com/en/actions/guides/caching-dependencies-to-speed-up-workflows#matching-a-cache-key">read the docs thoroughly</a>, including the examples, as it may reveal the root cause.</p> <p>You will not want, for instance, to share the same prefix between 2 jobs that have no Docker layer in common (e.g. a <em>FROM alpine</em> and a <em>FROM debian</em> may not), otherwise each one might match the cache of the other one, increasing its size by adding its own layers but without finding any layer to reuse.</p> <p>In the following execution trace of the <em>Cache Docker layers</em> step, we see that although we are in the section that builds the <em>debian</em> image (<code class="language-plaintext highlighter-rouge">key: Linux-buildx-debian-9176c5bd644818205d94a68221a7ebf27005b30e</code>), it hits the previous cache from the <em>alpine</em> image (<code class="language-plaintext highlighter-rouge">Cache restored from key: Linux-buildx-alpine-75bd3133c854ab90910b7ceb92445fafbe256260</code>), which has little chance to provide the layers it needs :</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Run actions/cache@v2
  with:
    path: /tmp/.buildx-cache
    key: Linux-buildx-debian-9176c5bd644818205d94a68221a7ebf27005b30e
    restore-keys: Linux-buildx-debian-
  Linux-buildx-

  env:
    pythonLocation: /opt/hostedtoolcache/Python/3.9.1/x64
    LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.1/x64/lib
    DEBIAN_TAGS: ***/nicobot:dev-debian
    SIGNAL_DEBIAN_TAGS: ***/nicobot:dev-signal-debian
    ALPINE_TAGS: ***/nicobot:dev-alpine
    NICOBOT_VERSION: 0.1.dev1
Received 67108864 of 4381819546 (1.5%), 63.8 MBs/sec
Received 218103808 of 4381819546 (5.0%), 103.8 MBs/sec
[...]
Cache Size: ~4179 MB (4381819546 B)
/bin/tar --use-compress-program zstd -d -xf /home/runner/work/_temp/3eafeb81-b970-4b87-9515-d659390d4387/cache.tzst -P -C /home/runner/work/nicobot/nicobot
Cache restored from key: Linux-buildx-alpine-75bd3133c854ab90910b7ceb92445fafbe256260
</code></pre></div></div> <p>A more efficient use of GA cache here would be to make sure they target separate caches so they can be evicted separately. This can be done by limiting the <code class="language-plaintext highlighter-rouge">restore-keys</code> to non-overlapping values :</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache Docker layers</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v2</span>
  <span class="na">with</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/tmp/.buildx-cache</span>
      <span class="na">key</span><span class="pi">:</span> <span class="s">$-buildx-debian-$</span>
      <span class="na">restore-keys</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">$-buildx-debian-</span>

<span class="s">...</span>

<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache Docker layers</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v2</span>
  <span class="na">with</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/tmp/.buildx-cache</span>
      <span class="na">key</span><span class="pi">:</span> <span class="s">$-buildx-alpine-$</span>
      <span class="na">restore-keys</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">$-buildx-alpine-</span>
</code></pre></div></div> <h2 id="conclusion">Conclusion</h2> <p>Out of the box, <em>GitHub Actions</em> allows to quickly set up continuous integration workflows for very basic requirements.</p> <p>First make sure to design your workflows so that they <strong>take advantage of parallel building</strong>. Think about the dependencies between your steps.</p> <p>Caching is another key factor to faster builds : the <strong>actions/cache@v2</strong> action can greatly improve the speed of the builds (x5 to x9 !). However, to use it right, this action requires a deep understanding of its internal workflow and the current limit to 5GB may compel you to spin custom runners or add your own storage, if your build regularly exceeds this limit. You may also not need to use such a cache if your build only takes a few minutes to complete, as downloading &amp; saving the cache adds an overhead to the total execution time.</p> <p>This article showed some tips and workarounds to get the maximum of <em>actions/cache</em> : by combining some of those practices <strong>I was able to speed up repeated builds of 3 complex images from 1h50 to 10 minutes…</strong></p> <p>My final word would be to <strong>build &amp; test a maximum on your workstation</strong> so you won’t need to spend time on the tricky parts of this article. Once your build has become stable you will not bother waiting from time to time for it to end, as you will be confident that it will succeed in one attempt. For a lot of Docker build scenarios parallelization and basic caching alone will be sufficient.</p> <h2 id="references">References</h2> <ul> <li><a href="https://github.com/actions/cache">actions/cache</a></li> <li><a href="https://github.com/whoan/docker-build-with-cache-action">whoan/docker-build-with-cache-action</a></li> <li><a href="https://github.com/sdras/awesome-actions">Awesome Actions</a></li> <li><a href="https://docs.github.com/en/actions/guides/storing-workflow-data-as-artifacts">Storing &amp; retrieving <em>github artifacts</em></a></li> </ul> <aside class="tags"> <ul class="tags"> <li class="tag"><a href="/tags#docker">#docker</a></li> <li class="tag"><a href="/tags#github">#github</a></li> <li class="tag"><a href="/tags#github-actions">#github actions</a></li> <li class="tag"><a href="/tags#ci">#ci</a></li> </ul> </aside> <aside class="share"> <strong>Share this :</strong> <a href="http://twitter.com/share?text=Speed up your automated Docker builds with GitHub Actions&amp;url=https://www.nicolabs.net/2021/Speed-up-automated-docker-build-with-github-actions&amp;hashtags=web,dev,blog,soudev&amp;via=nic0b0" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">Twitter</a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://www.nicolabs.net/2021/Speed-up-automated-docker-build-with-github-actions" onclick="window.open(this.href, 'facebook-share', 'width=550,height=235');return false;">Facebook</a> </aside> </div> </article> <footer class="site-footer"> <div class="container"> <small class="pull-left">&copy;2023 All rights reserved.</small> <small class="pull-right">by <a rel="me" href="/about#contact">@nicobo</a></small> </div> </footer> </main> </body> </html>
